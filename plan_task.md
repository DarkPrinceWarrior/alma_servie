Пайплайн

  - 1. Конфигурация и структура: оформить репозиторий (src/, data/raw|interim|processed, notebooks/, reports/), вынести параметры (шаблоны
    колонок, правила фильтрации, условия аномалий) в config. Подготовить скрипт для загрузки исходных Excel в data/raw и фиксации метаданных
    (список файлов, хэши, дата выкачки).
  - 2. Импорт и первичная валидация: из каждого Excel собрать два датафрейма (АГЗУ и СУ), логгировать отсутствующие листы/колонки; сравнивать
    структуры c эталоном из config. Результат сохранять в data/interim/agzu_raw.parquet и .../su_raw.parquet вместе со списком найденных
    проблем.
  - 3. Контроль качества сырья: на промежуточных данных построить отчёты (разрывы >24 ч, дубликаты, отрицательные/экстремальные значения,
    доля нулей, распределение NaN) и выгружать их в reports/qc/*.html. Итог чек-листа согласовывать с технологами, отмечая участки простоя и
    допустимые диапазоны.
  - 4. Очистка и заполнение: применять утверждённые правила:
      - SU: оставляем нули как факт, NaN закрываем ffill→bfill по скважине, при необходимости маркируем длительные нулевые плато.
      - AGZU: внедряем выбранную стратегию (например, не заполнять разрывы >24 ч, короткие пробелы — интерполировать или тянуть назад) +
        фильтруем/обрезаем согласованные выбросы.
      - результаты пишем в data/processed/agzu_clean.parquet/su_clean.parquet и фиксируем долю изменённых точек.
  - 5. Приведение к общей временной шкале: ресемплинг (часовой или иной) и агрегирование по скважинам; синхронизация АГЗУ и СУ через merge_asof
    или объединённую сетку, хранение в data/processed/merged.parquet. Приложить статистику потерь/добавленных точек.
  - 6. Подготовка окон для аномалий: загрузить таблицу условий, преобразовать даты, сформировать для каждой скважины пары выборок («3 дня до» и
    «период») по чистым данным. Считать средние/медианы и относительные изменения по нужным колонкам, формируя features_anomaly.parquet.
  - 7. Применение условий аномалии: формализовать правила (пороговые интервалы, направление изменений). Построить модуль, который по
    features_anomaly.parquet отмечает, выполнены ли условия, и заносит итог (аномалия/нет) с дополнительными показателями чувствительности.
  - 8. Выходные артефакты и визуализация: собрать итоговый Excel/CSV + интерактивные отчёты (тепловые карты, временные графики), сохранять в
    reports/anomalies/. Автоматически прикладывать QC-резюме и лог расчетов.
  - 9. Автоматизация: завернуть шаги 2–8 в CLI/Orchestrator (например, python -m pipeline run --since …), обеспечить логирование, обработку
    ошибок и unit-тесты для критичных функций (парсинг дат, заполнение пропусков, вычисление процентов). Настроить CI/CD или расписание, если
    пайплайн будет регулярным.